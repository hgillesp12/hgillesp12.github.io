<!DOCTYPE HTML>
<html>
	<head>
		<title>Hannah Gillespie</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=1000">
		<link rel="stylesheet" href="https://use.typekit.net/quv7bsd.css"> <!-- fonts -->
		<link rel="stylesheet" href="style.css" />
	</head>
	<body id="body">
		<div id="main">
			<header id="navbar">
				<a href="index.html">Home</a>
				<a href="portfolio.html">Portfolio</a>
                <button id="dark-toggle" class="button-mode">
					<img id="toggle-icon" src="images/buttons/dark_mode.jpg" alt="Toggle Dark Mode">
				</button>
			</header>
            
			<div class="section portfolio">
				<h2>Using drones to inspect Great Britain's oaks</h2>

				<div class="portfolio-proj">
					<a href="https://github.com/hgillesp12/aod_detection" target="_blank" class="portfolio-proj-title">Detection of Acute Oak Decline Risk
                        Levels by Unmanned Aerial Vehicle
                        with Real-Time Deep Learning</a>
					<br>
					<p>Structured field surveys are essential for monitoring the spread of Acute Oak Decline
                        (AOD), a novel polybacterial disease affecting oak trees in the United Kingdom. Traditional 
                        methods for collecting below-canopy forest health data, such as volunteer
                        reporting or ground surveys conducted by citizen science groups, are often unstructured, 
                        manual, and time-consuming. Unmanned aerial vehicles (UAVs) equipped
                        with commercial RGB cameras offer a more efficient approach for conducting structured, 
                        below-canopy, trunk-based surveys over challenging terrain. This study proposes a supervised 
                        learning framework to (1) distinguish oak trees from other tree
                        species in each image, and (2) assess the “risk” level of each oak tree for AOD infection. 
                        A custom one-stage object detector model, based on YOLOv5, was trained on
                        a dataset comprising both real and synthetic images. The model achieved a maximum mean
                        average precision (mAP) of 90.2% at an Intersection-over-Union (IoU) threshold
                        of 0.5 (50%) across all classes. Notably, the model demonstrated a recall rate of
                        91.8% for the high-risk oak class, indicating a high sensitivity in detecting trees at
                        the greatest risk for AOD infection. Experiments were conducted in a simulation
                        environment at a frame rate of 13-15 FPS, and field tests were performed at the
                        National Trust's Attingham Park site. While the model shows some variability in 
                        distinguishing oak trees from non-oak trees, it aligns reasonably well with health risk
                        assessments conducted by Forest Research UK experts, demonstrating its potential
                        utility for large-scale forest health monitoring.<br></p>
                        <p>
                            <a href="https://github.com/hgillesp12/aod_detection" target="_blank">GitHub</a>
                        </p>
                        <h3>Please scroll to view this project:</h3>
                        <div class="section recent-work">
                            <div class="slider">
                                <a href="images/drone_thesis_imperial/labels.png" target="_blank"><img src="images/drone_thesis_imperial/labels.png"></a>
                                <a href=""><img src="images/drone_thesis_imperial/trees.png"></a>
                                <a href=""><img src="images/drone_thesis_imperial/augment.png"></a>
                                <a href=""><img src="images/drone_thesis_imperial/prcurve.png"></a>
                                <a href=""><img src="images/drone_thesis_imperial/blender.png"></a>
                                <a href=""><img src="images/drone_thesis_imperial/recorded.png"></a>
                                <a href=""><img src="images/drone_thesis_imperial/streaming.png"></a>
                                <a href=""><img src="images/drone_thesis_imperial/drone.png"></a>
                            </div>
                        </div>
                </div>
			</div>
            <footer id="footer">
				<div class="footer-links">
					<a href="https://www.linkedin.com/in/hannahgillespie" target="_blank" rel="noopener noreferrer" class="button-link">
						<img src="images/buttons/linkedin.png" alt="LinkedIn">
					</a>
					<a href="https://github.com/hgillesp12" target="_blank" rel="noopener noreferrer" class="button-link">
						<img src="images/buttons/github.png" alt="GitHub">
					</a>
					<a href="files/Gillespie CV.pdf" target="_blank" rel="noopener noreferrer" class="button-link">
						<img src="images/buttons/cv.png" alt="View CV">
					</a>
					<button class="button-link" onclick="openModal()">
						<img src="images/buttons/email.png" alt="Email icon">
					</button>
				</div>
			</footer>
		</div>
	<!-- Modal structure -->
	<div id="contactModal" class="modal">
		<div class="modal-content">
		<span class="close" onclick="closeModal()">&times;</span>
		<h1 class="contact-heading">Contact</h1>
		<form action="https://formspree.io/f/manovarg" method="POST" class="contact-form">
			<label for="name">Your name:</label><br>
			<input type="text" id="name" name="name" required><br><br>
	
			<label for="email">Your email:</label><br>
			<input type="email" id="email" name="email" required><br><br>
	
			<label for="message">Your message:</label><br>
			<textarea id="message" name="message" rows="6" required></textarea><br><br>
	
			<button type="submit" class="contact-button">Send</button>
		</form>
		</div>
	</div>
    <script>
		// Cache references
		const body = document.body;
		const toggleBtn = document.getElementById('dark-toggle');
		const toggleIcon = document.getElementById('toggle-icon');
		const darkIcon = 'images/buttons/dark_mode.jpg'; 
		const lightIcon = 'images/buttons/light_mode.jpg';   
		
		// Load saved preference on page load
		if (localStorage.getItem('darkMode') === 'enabled') {
			body.classList.add('dark-mode');
			toggleIcon.src = lightIcon;  // light icon for light mode
		} else {
			toggleIcon.src = darkIcon;  // dark icon for dark mode
		}

		// Toggle dark mode function
		function toggleDarkMode() {
			body.classList.toggle('dark-mode');
			if (body.classList.contains('dark-mode')) {
				localStorage.setItem('darkMode', 'enabled');
				toggleIcon.src = lightIcon;
			} else {
				localStorage.setItem('darkMode', 'disabled');
				toggleIcon.src = darkIcon;
			}
		}

		// Attach event listener to button
		toggleBtn.addEventListener('click', toggleDarkMode);

		function openModal() {
			document.getElementById("contactModal").style.display = "flex";
			document.body.classList.add("modal-open");
		}

		function closeModal() {
			document.getElementById("contactModal").style.display = "none";
			document.body.classList.remove("modal-open");
		}

		window.onclick = function(event) {
		  const modal = document.getElementById("contactModal");
		  if (event.target === modal) {
			closeModal();
		  }
		}
		
		window.addEventListener('pageshow', function(event) {
		// 'pageshow' fires even when navigating back to the page.
		// Ensure the modal is hidden:
		const modal = document.getElementById('contactModal');
		if (modal) {
			modal.style.display = 'none';
		}
		});
	</script>
	</body>
</html>

